"""Dog-leg trust-region optimization."""
from __future__ import division, print_function, absolute_import

import numpy as np
import scipy.linalg
from ._trustregion import _help_solve_subproblem, _minimize_trust_region

__all__ = ['fmin_dogleg']


# This function provides an interface
# modeled on scipy.optimize.fmin_ncg().
def fmin_dogleg(f, x0, fprime, fhess, args=(),
        initial_trust_radius=1.0,
        max_trust_radius=1000.0,
        eta=0.15,
        gtol=1e-4,
        maxiter=None, full_output=False, disp=True,
        retall=False, callback=None):
    """
    Minimize a function using the dog-leg trust-region algorithm.

    This algorithm requires function values and first and second derivatives.
    It also performs a costly Hessian decomposition for most iterations,
    and the Hessian is required to be positive definite.

    Parameters
    ----------
    f : callable ``f(x, *args)``
        Objective function to be minimized.
    x0 : ndarray
        Initial guess.
    fprime : callable ``f'(x, *args)``
        Gradient of f.
    fhess : callable ``fhess(x, *args)``
        Function to compute the Hessian matrix of f.
    args : tuple, optional
        Extra arguments passed to f, fprime, and fhess
        (the same set of extra arguments is supplied to all of
        these functions).
    initial_trust_radius : float, optional
        initial trust radius
    max_trust_radius : float, optional
        never propose steps that are longer than this value
    eta : float, optional
        trust region related acceptance stringency for proposed steps
    gtol : float, optional
        Gradient norm must be less than `gtol`
        before successful termination.
    maxiter : int, optional
        Maximum number of iterations to perform.
    full_output : bool, optional
        If True, return the optional outputs.
    disp : bool, optional
        If True, print convergence message.
    retall : bool, optional
        If True, return a list of results at each iteration
    callback : callable, optional
        An optional user-supplied function which is called after
        each iteration.  Called as callback(xk), where xk is the
        current parameter vector.

    Returns
    -------
    xopt : ndarray
        Parameters which minimize f, i.e. ``f(xopt) == fopt``.
    fopt : float
        Value of the function at xopt, i.e. ``fopt = f(xopt)``.
    fcalls : int
        Number of function calls made.
    gcalls : int
        Number of gradient calls made.
    hcalls : int
        Number of hessian calls made.
    warnflag : int
        Warnings generated by the algorithm.
        1 : Maximum number of iterations exceeded.
        2 : A bad approximation causes failure to predict improvement.
        3 : Linear algebra error such as a non-positive-definite Hessian.
    allvecs : list
        Results at each iteration.  Only returned if retall is True.

    See also
    --------
    minimize: Interface to minimization algorithms for multivariate
        functions.  See the 'dogleg' `method` in particular.

    References
    ----------
    .. [1] Jorge Nocedal and Stephen Wright,
           Numerical Optimization, second edition,
           Springer-Verlag, 2006, page 73.

    """
    opts = {'initial_trust_radius': initial_trust_radius,
            'max_trust_radius': max_trust_radius,
            'eta': eta,
            'gtol': gtol,
            'disp': disp,
            'maxiter': maxiter,
            'return_all': retall}

    res = _minimize_trust_region(
            f, x0, args, jac=fprime, hess=fhess,
            solve_subproblem=_solve_subproblem_dogleg,
            callback=callback, **opts)

    if full_output:
        retlist = (res['x'], res['fun'], res['nfev'], res['njev'],
                res['nhev'], res['status'])
        if retall:
            retlist += (res['allvecs'], )
        return retlist
    else:
        if retall:
            return res['x'], res['allvecs']
        else:
            return res['x']


def _solve_subproblem_dogleg(m, trust_radius):
    """
    The dogleg method.

    Parameters
    ----------
    m : LazyLocalQuadraticModel
        The quadratic model of the objective function.
    trust_radius : float
        We are allowed to wander only this far away from the origin.

    Returns
    -------
    p : ndarray
        The proposed step.
    hits_boundary : bool
        True if the proposed step is on the boundary of the trust region.

    Notes
    -----
    The Hessian is required to be positive definite.

    This function is called by the `_minimize_trust_region` function.
    It is not supposed to be called directly.
    """

    # Compute the Newton point.
    # This is the optimum for the quadratic model function.
    # If it is inside the trust radius then return this point.
    p_best = m.newton_point()
    if scipy.linalg.norm(p_best) < trust_radius:
        hits_boundary = False
        return p_best, hits_boundary

    # Compute the Cauchy point.
    # This is the predicted optimum along the direction of steepest descent.
    p_u = m.cauchy_point()

    # If the Cauchy point is outside the trust region,
    # then return the point where the path intersects the boundary.
    p_u_norm = scipy.linalg.norm(p_u)
    if p_u_norm >= trust_radius:
        p_boundary = p_u * (trust_radius / p_u_norm)
        hits_boundary = True
        return p_boundary, hits_boundary

    # Compute the intersection of the trust region boundary
    # and the line segment connecting the Cauchy and Newton points.
    # This requires solving a quadratic equation.
    # ||p_u + t*(p_best - p_u)||**2 == trust_radius**2
    # Solve this for positive time t using the quadratic formula.
    ta, tb = _help_solve_subproblem(p_u, p_best - p_u, trust_radius)
    p_boundary = p_u + tb * (p_best - p_u)
    hits_boundary = True
    return p_boundary, hits_boundary

